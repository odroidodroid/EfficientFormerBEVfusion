voxel_size: [0.075, 0.075, 0.2]
point_cloud_range: [-54.0, -54.0, -5.0, 54.0, 54.0, 3.0]

model:
  encoders:
    camera:
      backbone:
        type: ViT
        img_size : 704
        patch_size : 16
        embed_dim : 768
        depth : 12
        num_heads : 12
        drop_path_rate : 0.1
        window_size : 14
        mlp_ratio : 4
        qkv_bias : true
        window_block_indexes : [0,1,3,4,6,7,9,10]
        use_rel_pos : True
        norm_cfg :
          type : LN
          requires_grad : true
        init_cfg :
          type : Pretrained
          checkpoint : pretrained/mae_pretrain_vit_base.pth
      neck:
        type : SimpleFPN
        backbone_channel : 768
        in_channels : [192, 384, 768, 768]
        out_channels : 256
        num_outs : 3
        norm_cfg :
          type : LN2d
          requires_grad : true
      vtransform:
        in_channels: 256
        out_channels: 80
        image_size: ${image_size}
        feature_size: ${[image_size[0] // 8, image_size[1] // 8]}
        xbound: [-54.0, 54.0, 0.3]
        ybound: [-54.0, 54.0, 0.3]
        zbound: [-10.0, 10.0, 20.0]
        dbound: [1.0, 60.0, 0.5]
        downsample: 2
    lidar:
      voxelize:
        point_cloud_range: ${point_cloud_range}
        voxel_size: ${voxel_size}
        max_voxels: [120000, 160000]
      backbone:
        sparse_shape: [1440, 1440, 41]

  heads:
    object:
      train_cfg:
        grid_size: [1440, 1440, 41]
      test_cfg:
        grid_size: [1440, 1440, 41]

lr_config:
  policy: CosineAnnealing
  warmup: linear
  warmup_iters: 500
  warmup_ratio: 0.33333333
  min_lr_ratio: 1.0e-3
